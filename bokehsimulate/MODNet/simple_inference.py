"""
ç®€å•çš„å•å›¾æ¨ç†æ¼”ç¤º - å¿«é€Ÿæµ‹è¯•è„šæœ¬
ç”¨æ³•: python simple_inference.py <è¾“å…¥å›¾ç‰‡è·¯å¾„> [è¾“å‡ºè·¯å¾„]
"""

import os
import sys
import argparse
import numpy as np
from PIL import Image

import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.transforms as transforms

from src.models.modnet import MODNet


def infer_single_image(image_path, output_path, ckpt_path, device='cuda', ref_size=512):
    """
    å¯¹å•å¼ å›¾ç‰‡è¿›è¡Œæ¨ç†
    
    Args:
        image_path: è¾“å…¥å›¾ç‰‡è·¯å¾„
        output_path: è¾“å‡ºmatteè·¯å¾„
        ckpt_path: æ¨¡å‹æƒé‡è·¯å¾„
        device: è®¡ç®—è®¾å¤‡ ('cuda' æˆ– 'cpu')
        ref_size: å‚è€ƒå¤§å°
    
    Returns:
        matte: numpyæ•°ç»„ï¼Œå€¼èŒƒå›´[0, 1]
    """
    # å®šä¹‰è½¬æ¢
    im_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

    # è¯»å–å›¾åƒ
    print(f'ğŸ“– è¯»å–å›¾ç‰‡: {image_path}')
    im = Image.open(image_path)
    im_size = im.size
    print(f'   å›¾ç‰‡å°ºå¯¸: {im_size}')
    
    # ç»Ÿä¸€å›¾åƒé€šé“ä¸º3
    im = np.asarray(im)
    if len(im.shape) == 2:
        im = im[:, :, None]
    if im.shape[2] == 1:
        im = np.repeat(im, 3, axis=2)
    elif im.shape[2] == 4:
        im = im[:, :, 0:3]

    # è½¬æ¢ä¸ºPyTorchå¼ é‡
    im = Image.fromarray(im)
    im = im_transform(im)
    im = im[None, :, :, :]  # [1, 3, H, W]
    
    im_b, im_c, im_h, im_w = im.shape

    # è°ƒæ•´å¤§å°ä»¥åŒ¹é…å‚è€ƒå¤§å°
    if max(im_h, im_w) < ref_size or min(im_h, im_w) > ref_size:
        if im_w >= im_h:
            im_rh = ref_size
            im_rw = int(im_w / im_h * ref_size)
        else:
            im_rw = ref_size
            im_rh = int(im_h / im_w * ref_size)
    else:
        im_rh = im_h
        im_rw = im_w

    im_rw = im_rw - im_rw % 32
    im_rh = im_rh - im_rh % 32

    print(f'   è°ƒæ•´å¤§å°: ({im_h}, {im_w}) -> ({im_rh}, {im_rw})')
    
    im_resized = F.interpolate(im, size=(im_rh, im_rw), mode='area')

    # åˆ›å»ºæ¨¡å‹å¹¶åŠ è½½æƒé‡
    print(f'ğŸ¤– åŠ è½½æ¨¡å‹: {ckpt_path}')
    modnet = MODNet(backbone_pretrained=False)
    modnet = nn.DataParallel(modnet)

    if device == 'cuda' and torch.cuda.is_available():
        modnet = modnet.cuda()
        weights = torch.load(ckpt_path)
        print(f'   è®¾å¤‡: GPU (CUDA)')
    else:
        weights = torch.load(ckpt_path, map_location=torch.device('cpu'))
        device = 'cpu'
        print(f'   è®¾å¤‡: CPU')
    
    modnet.load_state_dict(weights)
    modnet.eval()

    # æ¨ç†
    print(f'ğŸ”„ æ¨ç†ä¸­...')
    with torch.no_grad():
        if device == 'cuda':
            im_resized = im_resized.cuda()
        _, _, matte = modnet(im_resized, True)

    # æ¢å¤åŸå§‹å¤§å°
    matte = F.interpolate(matte, size=(im_h, im_w), mode='area')
    matte = matte[0][0].data.cpu().numpy()
    
    # ä¿å­˜ç»“æœ
    os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else '.', exist_ok=True)
    Image.fromarray(((matte * 255).astype('uint8')), mode='L').save(output_path)
    
    print(f'âœ… æˆåŠŸä¿å­˜: {output_path}')
    print(f'   MatteèŒƒå›´: [{matte.min():.3f}, {matte.max():.3f}]')
    
    return matte


def main():
    parser = argparse.ArgumentParser(description='MODNet - ç®€å•æ¨ç†æ¼”ç¤º')
    parser.add_argument('input', type=str, nargs='?', default='pics/0.jpg', help='è¾“å…¥å›¾ç‰‡è·¯å¾„')
    parser.add_argument('output', type=str, nargs='?', default=None, help='è¾“å‡ºmatteè·¯å¾„ï¼ˆå¯é€‰ï¼‰')
    parser.add_argument('--ckpt', type=str, default='pretrained/modnet_photographic_portrait_matting.ckpt',help='æ¨¡å‹æƒé‡è·¯å¾„')
    parser.add_argument('--device', type=str, default='auto',help='è®¡ç®—è®¾å¤‡: cuda/cpu/auto')
    parser.add_argument('--ref-size', type=int, default=512, help='å‚è€ƒå¤§å°')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f'âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {args.input}')
        sys.exit(1)
    
    # ç¡®å®šè¾“å‡ºè·¯å¾„
    if args.output is None:
        base_name = os.path.splitext(os.path.basename(args.input))[0]
        args.output = os.path.join('resultMatting', f'{base_name}_matte.png')
    elif not args.output.endswith(('.png', '.jpg', '.jpeg')):
        args.output = f'{args.output}_matte.png'
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if not os.path.exists(args.ckpt):
        print(f'âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {args.ckpt}')
        sys.exit(1)
    
    # ç¡®å®šè®¾å¤‡
    if args.device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = args.device

    print(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    print(f'\n{"="*50}')
    print(f'MODNet äººåƒMattingæ¨ç†')
    print(f'{"="*50}\n')
    
    try:
        matte = infer_single_image(args.input, args.output, args.ckpt, device, args.ref_size)
        print(f'\n{"="*50}')
        print(f'æ¨ç†å®Œæˆï¼')
        print(f'{"="*50}\n')
    except Exception as e:
        print(f'\nâŒ æ¨ç†å¤±è´¥: {str(e)}')
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
