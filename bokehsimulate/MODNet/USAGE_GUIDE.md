# ğŸ¯ MODNet äººåƒMattingå®Œæ•´ä½¿ç”¨æŒ‡å—

## ğŸ“ é¡¹ç›®ä»‹ç»

MODNetæ˜¯ä¸€ä¸ª**å®æ—¶äººåƒæŠ å›¾æ¨¡å‹**ï¼Œå¯ä»¥ä»RGBå›¾åƒç›´æ¥ç”ŸæˆAlpha Matteï¼ˆé€æ˜åº¦å›¾ï¼‰ã€‚æ— éœ€trimapè¾“å…¥ï¼Œç›´æ¥è¾“å‡ºé«˜è´¨é‡çš„äººåƒè’™ç‰ˆã€‚

é¢„è®­ç»ƒæ¨¡å‹ï¼š`modnet_photographic_portrait_matting.ckpt`

**ç‰¹ç‚¹**ï¼š
- âœ… MODNetæ¨¡å‹ä»£ç ï¼ˆ`src/models/modnet.py`ï¼‰
- âœ… é¢„è®­ç»ƒæƒé‡æ–‡ä»¶ï¼ˆ`pretrained/modnet_photographic_portrait_matting.ckpt`ï¼‰
- âœ… å®Œæ•´çš„æ¨ç†è„šæœ¬

---

## ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿä¸Šæ‰‹

### æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥ï¼ˆå¿…åšï¼‰
```bash
# é¦–å…ˆæ£€æŸ¥ç¯å¢ƒå’Œä¾èµ–
python check_environment.py
```

è¿™ä¸ªè„šæœ¬ä¼šæ£€æŸ¥ï¼š
- âœ… Pythonç‰ˆæœ¬ >= 3.6
- âœ… PyTorchå®‰è£…
- âœ… CUDAå¯ç”¨æ€§
- âœ… ä¾èµ–åŒ…ï¼ˆpillow, numpyç­‰ï¼‰
- âœ… MODNetä»£ç æ–‡ä»¶
- âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨
- âœ… æ¨¡å‹èƒ½å¦æ­£å¸¸åŠ è½½

### æ­¥éª¤2: å•å¼ å›¾ç‰‡æ¨ç†ï¼ˆæ¨èå…ˆè¯•è¿™ä¸ªï¼‰

**æœ€ç®€å•çš„ç”¨æ³•**ï¼š
```bash
python simple_inference.py "ä½ çš„å›¾ç‰‡.jpg"
```

**æŒ‡å®šè¾“å‡ºè·¯å¾„**ï¼š
```bash
python simple_inference.py "ä½ çš„å›¾ç‰‡.jpg" "è¾“å‡ºæ–‡ä»¶å¤¹/è¾“å‡º.png"

# ä½¿ç”¨CPUï¼ˆå¦‚æœæ²¡æœ‰GPUï¼‰
python simple_inference.py "ä½ çš„å›¾ç‰‡.jpg" --device cpu
```

**Windowsç¤ºä¾‹**ï¼š
```bash
python simple_inference.py "C:\Users\ä½ çš„ç”¨æˆ·å\Desktop\portrait.jpg" "output.png"
```

### æ­¥éª¤3: æ‰¹é‡å¤„ç†å¤šå¼ å›¾ç‰‡
```bash
# åˆ›å»ºè¾“å…¥å’Œè¾“å‡ºæ–‡ä»¶å¤¹
mkdir test_images output_mattes

# å¤åˆ¶ä½ çš„å›¾ç‰‡åˆ° test_images æ–‡ä»¶å¤¹

# è¿è¡Œæ‰¹é‡æ¨ç†
python run_portrait_matting.py --input-path test_images --output-path output_mattes
```

---

## âš™ï¸ ç¯å¢ƒé…ç½®

### 1. æ£€æŸ¥Pythonç‰ˆæœ¬
```bash
python --version  # é¡» >= Python 3.6
```

### 2. å®‰è£…ä¾èµ–
```bash
pip install torch torchvision pillow numpy
```

> ğŸ’¡ å¦‚æœéœ€è¦GPUåŠ é€Ÿï¼Œè¯·å…ˆå®‰è£…å¯¹åº”çš„CUDAç‰ˆæœ¬PyTorchï¼š
> ```bash
> # CUDA 11.8ç‰ˆæœ¬
> pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
> 
> # CUDA 12.1ç‰ˆæœ¬
> pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
> ```

---

## ğŸ“Š ä»€ä¹ˆæ˜¯Alpha Matte?

Alpha Matteæ˜¯å›¾åƒçš„**é€æ˜åº¦å›¾**ï¼ˆç°åº¦å›¾ï¼‰ï¼š
- **é»‘è‰² (0)** = å®Œå…¨é€æ˜ï¼ˆèƒŒæ™¯ï¼‰
- **ç™½è‰² (255)** = å®Œå…¨ä¸é€æ˜ï¼ˆäººç‰©ï¼‰
- **ç°è‰² (128)** = åŠé€æ˜ï¼ˆå¤´å‘ç­‰è¾¹ç•Œï¼‰

### ä½¿ç”¨Alpha Matteçš„ç¤ºä¾‹ï¼š

**1. æ›¿æ¢èƒŒæ™¯**
```python
from PIL import Image
import numpy as np

# è¯»å–åŸå›¾å’Œmatte
image = Image.open('portrait.jpg')
matte = Image.open('portrait_matte.png')

# åˆ›å»ºRGBAå›¾åƒ
rgba = image.convert('RGBA')
rgba.putalpha(matte)
rgba.save('portrait_with_alpha.png')
```

**2. æ¨¡ç³ŠèƒŒæ™¯**
```python
from PIL import Image, ImageFilter
import numpy as np

image = Image.open('portrait.jpg')
matte_arr = np.array(Image.open('portrait_matte.png')) / 255.0

# æ¨¡ç³ŠåŸå›¾èƒŒæ™¯
blurred = image.filter(ImageFilter.GaussianBlur(radius=15))

# æŒ‰matteæ··åˆ
for i in range(3):
    image_arr = np.array(image.split()[i])
    blurred_arr = np.array(blurred.split()[i])
    # å‰æ™¯ä¿æŒåŸæ ·ï¼ŒèƒŒæ™¯ä½¿ç”¨æ¨¡ç³Šç‰ˆæœ¬

result = Image.new('RGB', image.size)
result.save('blurred_background.jpg')
```

---

## ğŸ¯ è„šæœ¬è¯¦ç»†è¯´æ˜

### 1ï¸âƒ£ simple_inference.pyï¼ˆç®€å•æ¨ç†ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šå•å¼ å›¾ç‰‡æˆ–å¿«é€Ÿæµ‹è¯•

```bash
python simple_inference.py <è¾“å…¥å›¾ç‰‡> [è¾“å‡ºè·¯å¾„] [é€‰é¡¹]

é€‰é¡¹:
  --ckpt PATH      æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆé»˜è®¤: pretrained/modnet_photographic_portrait_matting.ckptï¼‰
  --device DEVICE  cuda æˆ– cpuï¼ˆé»˜è®¤: è‡ªåŠ¨æ£€æµ‹ï¼‰
  --ref-size SIZE  å‚è€ƒå¤§å°ï¼Œé»˜è®¤512ï¼Œè¶Šå¤§è¶Šç²¾ç»†ä½†æ›´æ…¢
```

**è¾“å‡º**ï¼šå•ä¸ªPNGç°åº¦å›¾

**ç¤ºä¾‹**ï¼š
```bash
python simple_inference.py photo.jpg output_matte.png --ref-size 768
```

---

### 2ï¸âƒ£ run_portrait_matting.pyï¼ˆæ‰¹é‡æ¨ç†ï¼‰

**é€‚ç”¨åœºæ™¯**ï¼šå¤„ç†å¤§é‡å›¾ç‰‡

```bash
python run_portrait_matting.py \
  --input-path <è¾“å…¥æ–‡ä»¶å¤¹> \
  --output-path <è¾“å‡ºæ–‡ä»¶å¤¹> \
  [--ckpt PATH] \
  [--ref-size SIZE] \
  [--device DEVICE]

å¿…éœ€å‚æ•°:
  --input-path PATH   è¾“å…¥å›¾ç‰‡æ–‡ä»¶å¤¹
  --output-path PATH  è¾“å‡ºç»“æœæ–‡ä»¶å¤¹

å¯é€‰å‚æ•°:
  --ckpt PATH         æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤å€¼å·²è®¾ç½®ï¼‰
  --ref-size INT      å‚è€ƒå¤§å°ï¼ˆé»˜è®¤512ï¼‰
  --device DEVICE     è®¡ç®—è®¾å¤‡ï¼ˆé»˜è®¤è‡ªåŠ¨ï¼‰
```

**ç‰¹ç‚¹**ï¼š
- è‡ªåŠ¨è¯†åˆ«æ–‡ä»¶å¤¹å†…æ‰€æœ‰å›¾ç‰‡
- æ”¯æŒæ ¼å¼ï¼šJPGã€PNGã€BMPã€GIF
- è¿›åº¦æ˜¾ç¤º
- å‡ºé”™ç»§ç»­å¤„ç†

**ç¤ºä¾‹**ï¼š
```bash
python run_portrait_matting.py --input-path "D:\photos" --output-path "D:\results"
```

---

### 3ï¸âƒ£ check_environment.pyï¼ˆç¯å¢ƒæ£€æŸ¥ï¼‰

éªŒè¯æ‰€æœ‰ä¾èµ–å’Œé…ç½®æ˜¯å¦æ­£ç¡®ã€‚

```bash
python check_environment.py
```

**æ£€æŸ¥å†…å®¹**ï¼š
- âœ… Pythonç‰ˆæœ¬ >= 3.6
- âœ… PyTorchå®‰è£…
- âœ… CUDAå¯ç”¨æ€§
- âœ… ä¾èµ–åŒ…ï¼ˆpillow, numpyç­‰ï¼‰
- âœ… MODNetä»£ç æ–‡ä»¶
- âœ… æ¨¡å‹æ–‡ä»¶å­˜åœ¨
- âœ… æ¨¡å‹èƒ½å¦æ­£å¸¸åŠ è½½

---

## ğŸ”§ å‚æ•°ä¼˜åŒ–æŒ‡å—

### ref-size å‚æ•°ï¼ˆå¤„ç†å¤§å°ï¼‰

| å€¼ | å¤„ç†é€Ÿåº¦ | è´¨é‡ | å†…å­˜å ç”¨ | æ¨èåœºæ™¯ |
|----|--------|------|--------|--------|
| 256 | å¿«é€Ÿ | ä¸€èˆ¬ | å°‘ | å¿«é€Ÿæ¼”ç¤ºã€å°å±å¹• |
| 512 | å‡è¡¡ | ä¸­ç­‰ | ä¸­ | **é»˜è®¤å€¼** |
| 768 | è¾ƒæ…¢ | è¾ƒå¥½ | å¤š | é«˜è´¨é‡éœ€æ±‚ |
| 1024 | æ…¢ | ä¼˜ç§€ | å¾ˆå¤š | ä¸“ä¸šåº”ç”¨ |

```bash
# å¿«é€Ÿå¤„ç†
python simple_inference.py photo.jpg --ref-size 256

# é«˜è´¨é‡è¾“å‡º
python simple_inference.py photo.jpg --ref-size 1024
```

### device å‚æ•°ï¼ˆè®¡ç®—è®¾å¤‡ï¼‰

```bash
# è‡ªåŠ¨é€‰æ‹©ï¼ˆé»˜è®¤ï¼‰
python simple_inference.py photo.jpg --device auto

# å¼ºåˆ¶ä½¿ç”¨GPU
python simple_inference.py photo.jpg --device cuda

# å¼ºåˆ¶ä½¿ç”¨CPU
python simple_inference.py photo.jpg --device cpu
```

---

## ğŸ“ˆ æ€§èƒ½å‚è€ƒ

### GPU æ€§èƒ½ (NVIDIA RTX 3060)

| è¾“å…¥åˆ†è¾¨ç‡ | å¤„ç†æ—¶é—´ | è´¨é‡ |
|-----------|--------|------|
| 512x512   | ~20ms  | ä¸€èˆ¬ |
| 1024x1024 | ~40ms  | è¾ƒå¥½ |
| 2048x2048 | ~120ms | ä¼˜ç§€ |

### CPU æ€§èƒ½ (Intel i7)

| è¾“å…¥åˆ†è¾¨ç‡ | å¤„ç†æ—¶é—´ | è´¨é‡ |
|-----------|--------|------|
| 512x512   | ~200ms | ä¸€èˆ¬ |
| 1024x1024 | ~500ms | è¾ƒå¥½ |
| 2048x2048 | ~1500ms| ä¼˜ç§€ |

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
e:\debug\MODNet
â”œâ”€â”€ pretrained/
â”‚   â”œâ”€â”€ modnet_photographic_portrait_matting.ckpt  â† é¢„è®­ç»ƒæ¨¡å‹
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ modnet.py  â† MODNetæ¨¡å‹å®šä¹‰
â”‚   â”‚   â””â”€â”€ backbones/
â”‚   â”‚       â””â”€â”€ mobilenetv2.py  â† ä¸»å¹²ç½‘ç»œ
â”‚   â””â”€â”€ trainer.py
â”œâ”€â”€ demo/
â”‚   â”œâ”€â”€ image_matting/
â”‚   â”‚   â””â”€â”€ colab/inference.py  â† Colabæ¼”ç¤º
â”‚   â””â”€â”€ video_matting/
â”œâ”€â”€ simple_inference.py         â† âœ¨ ç®€å•æ¨ç†è„šæœ¬
â”œâ”€â”€ run_portrait_matting.py     â† âœ¨ æ‰¹é‡æ¨ç†è„šæœ¬
â”œâ”€â”€ check_environment.py        â† âœ¨ ç¯å¢ƒæ£€æŸ¥è„šæœ¬
â”œâ”€â”€ USAGE_GUIDE.md             â† è¿™ä¸ªæ–‡ä»¶
â””â”€â”€ README.md                  â† é¡¹ç›®è¯´æ˜
```

---

## ğŸ” è¾“å‡ºè§£é‡Š

- **è¾“å‡ºæ ¼å¼**: PNGç°åº¦å›¾åƒ
- **åƒç´ å€¼**: 0-255 (0=å®Œå…¨é€æ˜, 255=å®Œå…¨ä¸é€æ˜)
- **å‘½åè§„åˆ™**: `<è¾“å…¥å>_matte.png`

ä¾‹å¦‚ï¼š`photo.jpg` â†’ `photo_matte.png`

---

## ğŸ› å¸¸è§é—®é¢˜

### Q1: æ²¡æœ‰GPUæ€ä¹ˆåŠï¼Ÿ
**A**: è„šæœ¬ä¼šè‡ªåŠ¨æ£€æµ‹ï¼Œä½¿ç”¨CPUæ¨ç†ï¼ˆè¾ƒæ…¢ï¼‰ã€‚è¿è¡Œæ—¶æ— éœ€ä¿®æ”¹å‚æ•°ã€‚

### Q2: æ¨ç†é€Ÿåº¦å¤ªæ…¢ï¼Ÿ
**A**: 
- å‡å° `--ref-size` (é»˜è®¤512ï¼Œå¯æ”¹ä¸º256æˆ–384)
- ä½¿ç”¨GPUåŠ é€Ÿ (`--device cuda`)
- é™ä½è¾“å…¥å›¾åƒåˆ†è¾¨ç‡

### Q3: è¾“å‡ºè´¨é‡ä¸å¥½ï¼Ÿ
**A**:
- å¢åŠ  `--ref-size` (æ”¹ä¸º768æˆ–1024)
- ç¡®ä¿è¾“å…¥å›¾åƒæ¸…æ™°ï¼Œæœ€å¥½æ˜¯ä¸“ä¸šè‚–åƒç…§
- æ¨¡å‹é’ˆå¯¹ä¸“ä¸šè‚–åƒç…§ä¼˜åŒ–ï¼Œå¯èƒ½å¯¹å…¶ä»–ç…§ç‰‡æ•ˆæœä¸€èˆ¬

### Q4: æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Ÿ
**A**: ç¡®ä¿ `pretrained/modnet_photographic_portrait_matting.ckpt` å­˜åœ¨ã€‚
å¦‚æœä¸¢å¤±ï¼Œå¯ä»[Google Drive](https://drive.google.com/drive/folders/1umYmlCulvIFNaqPjwod1SayFmSRHziyR?usp=sharing)ä¸‹è½½ã€‚

### Q5: è¿è¡ŒæŠ¥é”™ "ModuleNotFoundError: No module named 'torch'"
**A**: å®‰è£…PyTorch
```bash
pip install torch torchvision
# æˆ–GPUç‰ˆæœ¬
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Q6: "CUDA out of memory"ï¼ˆæ˜¾å­˜ä¸è¶³ï¼‰
**A**:
- å‡å° `--ref-size` å‚æ•°
- ä½¿ç”¨ `--device cpu` æ”¹ç”¨CPU
- å…³é—­å…¶ä»–GPUç¨‹åº

### Q7: èƒ½å¦å¤„ç†è§†é¢‘ï¼Ÿ
**A**: å¯ä»¥ï¼Œå‚è€ƒ `demo/video_matting/` æ–‡ä»¶å¤¹ä¸­çš„è„šæœ¬ã€‚

---

## ğŸ¨ é«˜çº§ç”¨æ³•

### Pythonä»£ç é›†æˆ

#### æ–¹å¼1: å‘½ä»¤è¡Œé›†æˆ

```python
from PIL import Image
import torch
from src.models.modnet import MODNet
import torchvision.transforms as transforms
import torch.nn.functional as F

# åˆå§‹åŒ–æ¨¡å‹
modnet = MODNet(backbone_pretrained=False)
modnet = torch.nn.DataParallel(modnet)
weights = torch.load('pretrained/modnet_photographic_portrait_matting.ckpt')
modnet.load_state_dict(weights)
modnet.cuda()
modnet.eval()

# å‡†å¤‡å›¾åƒ
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])
im = Image.open('portrait.jpg')
im = transform(im)[None, :, :, :]  # [1, 3, H, W]

# æ¨ç†
with torch.no_grad():
    _, _, matte = modnet(im.cuda(), True)
    # matte shape: [1, 1, H, W], å€¼èŒƒå›´ [0, 1]
```

#### æ–¹å¼2: è‡ªå®šä¹‰ç±»å°è£…

```python
import torch
from PIL import Image
import torchvision.transforms as transforms
import torch.nn.functional as F
from src.models.modnet import MODNet

class PortraitMatter:
    def __init__(self, ckpt_path, device='cuda'):
        self.device = device
        self.model = MODNet(backbone_pretrained=False)
        self.model = torch.nn.DataParallel(self.model)
        
        weights = torch.load(ckpt_path, map_location=device)
        self.model.load_state_dict(weights)
        self.model.to(device)
        self.model.eval()
        
        self.transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
        ])
    
    def process(self, image_path, ref_size=512):
        """å¤„ç†å•å¼ å›¾ç‰‡"""
        image = Image.open(image_path)
        h, w = image.size
        
        # é¢„å¤„ç†
        im = self.transform(image)[None, :, :, :]
        
        # è°ƒæ•´å¤§å°
        if im.shape[2] > ref_size or im.shape[3] > ref_size:
            im = F.interpolate(im, size=(ref_size, ref_size), mode='area')
        
        # æ¨ç†
        with torch.no_grad():
            im = im.to(self.device)
            _, _, matte = self.model(im, True)
        
        # æ¢å¤åŸå§‹å¤§å°
        matte = F.interpolate(matte, size=(h, w), mode='area')
        return matte[0][0].cpu().numpy()

# ä½¿ç”¨ç¤ºä¾‹
matter = PortraitMatter('pretrained/modnet_photographic_portrait_matting.ckpt')
matte = matter.process('photo.jpg')
```

---

## ğŸ“– è®ºæ–‡å’Œå¼•ç”¨

å¦‚æœä½ ä½¿ç”¨äº†MODNetï¼Œè¯·å¼•ç”¨ä»¥ä¸‹è®ºæ–‡ï¼š

```bibtex
@article{MODNet2021,
  author    = {Ke, Zhanghan and Li, Kaican and Zhou, Yunmiao and Wu, Qiulin and Bao, Bingbing and Zhang, Wei and Sun, Mingming},
  title     = {MODNet: Real-Time Trimap-Free Portrait Matting via Objective Decomposition},
  journal   = {AAAI 2022},
  month     = {February},
  year      = {2022}
}
```

### ç›¸å…³èµ„æº

- ğŸ“„ è®ºæ–‡: [MODNet: Real-Time Trimap-Free Portrait Matting via Objective Decomposition](https://arxiv.org/pdf/2011.11961.pdf)
- ğŸ¥ åœ¨çº¿æ¼”ç¤º: https://zhke.io/#/?modnet_demo
- ğŸ“º è¡¥å……è§†é¢‘: https://youtu.be/PqJ3BRHX3Lc
- ğŸ’¾ å…¶ä»–æ ¼å¼: ONNX/TorchScriptç‰ˆæœ¬å¯ç”¨

---

## ğŸ“ æ¨èä½¿ç”¨æµç¨‹

1. âœ… è¿è¡Œ `python check_environment.py` éªŒè¯ç¯å¢ƒ
2. âœ… ç”¨ `python simple_inference.py <å›¾ç‰‡>` æµ‹è¯•å•å¼ å›¾ç‰‡
3. âœ… ç”¨ `python run_portrait_matting.py ...` æ‰¹é‡å¤„ç†
4. ğŸ”„ å°†matteç”¨äºä½ çš„é¡¹ç›®ï¼ˆèƒŒæ™¯æ›¿æ¢ã€è™šåŒ–ç­‰ï¼‰
5. ğŸ“– é˜…è¯»è®ºæ–‡äº†è§£ç®—æ³•åŸç†

---

**ç¥ä½¿ç”¨æ„‰å¿«ï¼æœ‰é—®é¢˜æ¬¢è¿åé¦ˆã€‚** ğŸš€
